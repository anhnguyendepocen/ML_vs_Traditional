---
title: "Pitfall of Prediction-orienterd Machine Learning Methods and Economic Value of Statistical Efficiency in On-farm Precision Experimentation"
author:
  - Taro Mieno^[University of Nebraska Lincoln, tmieno2@unl.edu], Xiaofei Li^[Mississippi State University, xiaofei.li@msstate.edu], David S. Bullock^[University of Illinois, dsbulloc@illinois.edu]
output:
  officedown::rdocx_document:
    toc: false
    toc_depth: 1
    number_sections: true
    reference_docx: "word_template.docx"
    plots:
      style: Normal
      align: center
      caption:
       style: Image Caption
       pre: "Figure "
       sep: ": "
    tables:
      style: Table
      layout: autofit
      width: 1.0
      caption:
       style: Table Caption
       pre: "Table "
       sep: ": "
# bibliography: PA.bib
# csl: american-journal-of-agricultural-economics.csl
abstract: ""
---

```{r echo = F, cache = F, include = F}
library(knitr)
library(here)

here::i_am("GitControlled/Writing/manuscript.rmd")

opts_chunk$set(
  fig.align = "center",
  fig.retina = 5,
  warning = F,
  message = F,
  cache = T,
  echo = F,
  fig.cap = TRUE
)
```

```{r cache = F, include = F}
#--- packages ---#
library(data.table)
library(tidyverse)
library(officedown)
library(officer)
library(flextable)
library(stringr)
library(sf)
library(lfe)
library(modelsummary)
library(patchwork)
library(gridExtra)
```

```{r figure_setup, cache = F}
theme_update(
  axis.title.x =
    element_text(
      size = 12, angle = 0, hjust = .5, vjust = -0.3, face = "plain"
    ),
  axis.title.y =
    element_text(
      size = 12, angle = 90, hjust = .5, vjust = .9, face = "plain"
    ),
  axis.text.x =
    element_text(
      size = 10, angle = 0, hjust = .5, vjust = 1.5, face = "plain"
    ),
  axis.text.y =
    element_text(
      size = 10, angle = 0, hjust = 1, vjust = 0, face = "plain"
    ),
  axis.ticks =
    element_line(
      size = 0.3, linetype = "solid"
    ),
  axis.ticks.length = unit(.15, "cm"),
  #--- legend ---#
  legend.text =
    element_text(
      size = 10, angle = 0, hjust = 0, vjust = 0, face = "plain"
    ),
  legend.title =
    element_text(
      size = 10, angle = 0, hjust = 0, vjust = 0, face = "plain"
    ),
  legend.key.size = unit(0.5, "cm"),
  #--- strip (for faceting) ---#
  strip.text = element_text(size = 10),
  #--- plot title ---#
  plot.title = element_text(family = "Times", face = "bold", size = 12),
  #--- margin ---#
  # plot.margin = margin(0, 0, 0, 0, "cm"),
  #--- panel ---#
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  panel.background = element_blank(),
  panel.border = element_rect(fill = NA)
)
```


```{r include = FALSE}
# /*===========================================================
#' # Prepare data and results for writing
# /*===========================================================
#* source all the functions in the Functions folder
# fs::dir_ls(here("Codes", "Functions"), full.names = TRUE) %>%
#   lapply(., function(x) source(x))

# /*----------------------------------*/
#' ##  data preparation
# /*----------------------------------*/
#' load results data
est_data <-
  readRDS(here("Shared", "Results", "est_result_ls.rds")) %>%
  rbindlist() %>%
  dplyr::select(model, perform, field_col) %>%
  unnest(perform) %>%
  data.table()
#' rename columns
est_data <- est_data %>%
  .[, .(field_col, model, sim, profit, rmse_train, rmse_cv, rmse_eonr)] %>%
  #---field size---
  .[, field_size := paste0(round(field_col * 72 * 6^2 / 10000, 1), " ha")] %>%
  .[, field_size := factor(field_size, levels = c("9.3 ha", "18.7 ha", "37.3 ha"))] %>%
  #---model name---
  .[model == "brf", model := "BRF"] %>%
  .[model == "rf", model := "RF"] %>%
  .[model == "rf_perfect", model := "RF_b"] %>%
  .[model == "lm", model := "OLS"] %>%
  .[model == "ser_50", model := "SER"] %>%
  .[, model := factor(model, levels = c("RF", "RF_b", "BRF", "OLS", "SER"))]
#' mean and sd
mean_data <- est_data %>%
  .[, .(
    profit = mean(profit) %>% round(2),
    profit_sd = sd(profit) %>% round(2),
    rmse_yield = mean(rmse_cv) %>% round(2),
    rmse_yield_sd = sd(rmse_cv) %>% round(2),
    rmse_eonr = mean(rmse_eonr) %>% round(2),
    rmse_eonr_sd = sd(rmse_eonr) %>% round(2)
  ),
  by = c("field_size", "model")
  ] %>%
  .[order(field_size, model), ]
#' load illustration data (single simulation)
illus_data <-
  readRDS(here("Shared", "Results", "illus_data.rds")) 

# /*----------------------------------*/
#' ##  create figures and tables
# /*----------------------------------*/
source(here("GitControlled", "Codes", "3_make_figures_tables.R"))
```

**Abstract**: 
 
**Keywords**: 

**Acknowledgement**: This research was supported by a USDA-NIFA-AFRI Food Security Program Coordinated Agricultural Project, titled “Using Precision Technology in On-farm Field Trials to Enable Data-Intensive Fertilizer Management,” (Accession Number 2016-68004-24769), and also by the a USDA-NRCS Conservation Innovation Grant from the On-farm Trials Program, titled “Improving the Economic and Ecological Sustainability of US Crop Production through On-Farm Precision Experimentation” (Award Number NR213A7500013G021).

`r run_pagebreak()`

# Introduction

Prediction-oriented ML methods swept the field of optimal input management as if yield prediction is the ultimate goal. RF in particular is used a lot. 

Apply ML without any clear purposes of how to use the trained models. 

+ Traditional vs ML (OLS, SER better than RF and BRF)
+ Yield prediction vs EONR prediction
+ Statistical efficiency is money (SER vs OLS)

The main purpose of this study is to compare the performance of prediction-oriented ML methods and traditional linear regression approaches in terms of the profitability of estimated site-specific nitrogen recommendation. Since the true site-specific EONR and maximum profit achievable is never observable for real fields, testing the statistical and economic properties of statistical methods have to rely on simulation analysis where the data generating process is known to the researcher. We conduct MC simulations for three different field sizes to test the economic performance of linear model OLS, linear model SER, Random Fores, and Boosted Regression Forest, where the true yield follows a quadratic plateau functional form. 

We found that while the prediction-oriented ML methods (RF and BRF) perform much better than the traditional methods (OLS and SER) in predicting yield level, they perform worse than the traditional methods (OLS and SER) in predicting EONR and thus in profitability of site-specific EONR recommendation. SER in particular performs the best in profitability. The economic value of its statistical efficiency over the OLS approach is not negligible at <span style = "color: blue;"> Xiafei, put numbers here </span>. Our results provide a cautionary tale for those who place unsubstantiated and blind trust in prediction-oriented ML methods and apply them when the accurate estimation of ceteris paribus causal impacts of the variable of interest is warranted. 

# Methods: Monte Carlo Simulation

In our Monte Carlo simulations, we will test five estimation approaches on three different sizes of fields: x ha, y ha, and x ha. In this section, we describe the data generating process, estimation approaches, and model evaluation. 

## Data Generation

Three simulated field of different sizes were created. Figure \@ref(fig:field-map) provides the map of a z-acre field as an example. The field consisted of $384$ 18.3 m $\times$ 73.2 m "plots," each of which was assigned an N fertilizer application rate. Each plot was made up of four (4-rows $\times$ 1-column) 18.3 m $\times$ 18.3 m "subplots," which were unit of analysis used in subsequent statistical analysis. Each subplot contained of a 6-rows $\times$ 6-columns grid of thirty-six 3.05 m $\times$ 3.05 m "cells." All field characteristics and yield data were generated at the cell level. 

Data were generated at the cell-level and then aggregated up to analysis-unit level (why). Cell-level yields were generated following the quadratic-plateau functional form as follows:

$$
\begin{aligned}
y_{i,j} = 
  \begin{cases}
  \alpha_{i,j} + \beta_{i,j} N + \gamma_{i,j} N^2 + \varepsilon_{i,j}, & N < \tau_{i,j} \\
  \eta_{i,j} + \varepsilon_{i,j}, & N \geq \tau_{i,j}
  \end{cases}
\end{aligned}
$$

In this formulation, yield increases as $N_{i,j}$ increase until $N_{i,j}$ reaches $\tau_{i,j}$, at which yield hits the plateau, $\eta_{i,j}$. The yield level at $N_{i,j}= 0$ is $\alpha_{i,j}$. The rate at which yield increases with respect to $N_{i,j}$ is governed by $\beta_{i,j}$ and $\gamma_{i,j}$. 

Farmers do not observe any of the parameters, but observe the decomposition of the parameters that given the yield response function. Specifically,

$$
\begin{aligned}
\alpha_{i,j} & = \alpha^1_{i,j} + \alpha^2_{i,j} \\
\tau_{i,j} & = min\big(min(\tau^{1,1}_{i,j}, \tau^{1,2}_{i,j}), min(\tau^{2,1}_{i,j}, \tau^{2,2}_{i,j})\big) \\
\eta_{i,j} & = min\big(min(\eta^{1,1}_{i,j}, \eta^{1,2}_{i,j}), min(\eta^{2,1}_{i,j}, \eta^{2,2}_{i,j})\big) 
\end{aligned}
$$

We denote the collection of covariate ($\alpha^1_{i,j}$, $\alpha^2_{i,j}$, $\tau^{1,1}_{i,j}$, $\tau^{1,2}_{i,j}$, $\tau^{2,1}_{i,j}$, $\tau^{2,2}_{i,j}$, $\eta^{1,1}_{i,j}$, $\eta^{1,2}_{i,j}$, $\eta^{2,1}_{i,j}$, $\eta^{2,2}_{i,j}$) as $X^1_{i,j}$. Note that $\alpha_{i,j}$, $\tau_{i,j}$, and $\eta_{i,j}$ (or equivalently $X^1_{i,j}$) have sufficient information to completely characterize the yield response function. This is because the coefficients $\beta_{i,j}$ and $\gamma_{i,j}$ are identified once $\alpha_{i,j}$, $\tau_{i,j}$, and $\eta_{i,j}$ are determined. These covariates are generated in a way that they are spatially correlated and also correlated with one another (Please see the codes available at <span style = "color: blue;"> gihutb account here</span>).

In addition to the covariates, two nuisance covariates that are correlated with each of $\alpha_{i,j}$, $\tau_{i,j}$, and $\eta_{i,j}$ are generated: $\phi^{\alpha, 1}_{i,j}$, $\phi^{\alpha, 2}_{i,j}$, $\phi^{\tau, 1}_{i,j}$, $\phi^{\tau, 2}_{i,j}$, $\phi^{\eta, 1}_{i,j}$, $\phi^{\eta, 2}_{i,j}$. We denote these variables as $X^2_{i,j}$. These variables are nuisance in the sense that they provide no additional information about the yield response functions once $X^1_{i,j}$ are included as covariates. Since they are correlated with $X^1_{i,j}$, the inclusion of $X^2_{i,j}$ would interfere with accurate identification of the $X^1_{i,j}$. We denote $X^1_{i,j}$ and $X^2_{i,j}$ collectively as $X_{i,j}$. Once the cell-level variables are generated, true economically optimal can be found by solving the profit maximization problem. This process is repeated 1000 times to create 1000 datasets. See Appendix \@ref(parameters) for maps of some of the covariates and true EONR for a single simulation round as an example. The cell level data were then aggregated up to the analysis unit level data: $\{y_i, X_i\}$.

## Estamation of yield response functions and site-specific optimal nitrogen rates

**Approach 1**: Linear Model OLS (Hereafter, OLS)

The OLS approach assumes a quadratic yield response function:

$$
\begin{aligned}
y_i = \beta_0 + \beta_1 \cdot N_i + \beta_2\cdot N_i^2 + N_i\cdot X_i\cdot \gamma_1 + N_i^2\cdot X_i\cdot \gamma_2 + \varepsilon
\end{aligned}
$$

where $\gamma_1$ and $\gamma_2$ are sets of interactions of $X_i$ with $N_i$, and $\varepsilon$ is the error term. The model is certainly misspecified because quadratic functions cannot perfectly represent yield response functions with a plateau (cite). It is known that the use of the quadratic functional form tends to over-estimate the true optimal nitrogen rate. However, it still approximates the underlying yield response functions quite well and is a popular functional form (cite). The _feols_ package in R was used to estimate the model (cite). 

**Approach 2**: Spatial Error Model (SER) 

The econometic model for the SER approach follows that of the OLS approach except for the error term.

$$
\begin{aligned}
y_i &= \beta_0 + \beta_1 \cdot N_i + \beta_2\cdot N_i^2 + N_i\cdot X_i\cdot \gamma_1 + N_i^2\cdot X_i\cdot \gamma_2 + \varepsilon \\
\varepsilon & = \lambda W \varepsilon + \mu
\end{aligned}
$$

where $\lambda$ is scaler that reflects the degree of spatial dependence, $W$ is the user-defined weight matrix, and $\mu$ is the idiosynctaric error term that is not spatially correlated. Estimation via the spatial error model takes into account the spatial dependency of the error term and thus statistically more  efficient than the OLS approach. The _spatialreg_ package in R was used to estimate the model (cite).  

**Approach 3**: Random Forest (RF)

Unlike the OLS and SER approaches, it does not assume any particular functional relationships between the dependent vairable and the covaraites. Random Forest consists of ensembles of trees. In each tree, the train data is split into a number of leaves based on the covirate values and all the observations belonging to the same leaf share the same yield estimate. Unlike a single classification and regression tree (CART), RF tends to avoid overfitting thanks to the averaging of estimates from the individual trees. The RF approach uses all the variables $(X_{i})$ as covariates.

**Approach 4**: best Random Forest (RF$_{best}$)

The RF$_{best}$ approach uses $\alpha$, $\beta$, and $\gamma$ directly to give a comparative advantage to RF relative to the other methods, instead of $(X_{i})$. 

**Approach 5**: Boosted Regression Forest (BRF)

While RF builds individual trees completely independent of one another, BRF build trees in a way that focuses relatively more on imroving the parts of the data that are not well explained in the previous sequence of trees. Consequently, BRF tends to perform better than RF in predicting yield. However, its use in the context of site-specific input management is limited compared to RF at the moment. The BRF approach uses all the covaraites in $X$ like the OLS, SER, and RF approaches. The _grf_ package in R was used to run the RF, RF$_{best}$, and BRF estimations (cite). Hyperparameters were tuned using cross-validation.  

For all the approches, once the yield response functions are estimated, site-specific EONR are calculated by numerically solving profit maximization problems at the cell level. Corn and nitrogen prices are assumed to be <span style = "color: blue;"> Xiaofei, put numbers here </span>. The codes to implement the MC simulations are publicly accessible at <span style = "color: blue;"> github account</span>. 

## Performance Measurement

For a given simulation round, we calculate root mean squared error (RMSE) of yield and EONR predictions and profit deficit for each approach. Profit deficit is defined as the true maximum profit less the profit obtained by following the estimated site-specifc EONR. To calculate these measures for a given simulation round, the dataset from another simulation round is used as the test dataset. This practice works as datasets across simulation rounds are created independently while following the same data generating process.


### Yield prediction

Root-mean-square error (RMSE) of yield prediction for a given simulation round is:

$$
\begin{aligned}
RMSE_{y} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)^2}
\end{aligned}
$$
where $y_i$ is the true yield of location $i$ from applying the trial N rate, and $\hat{y}_i$ is the predicted yield of the same location by a certain model. The total number of locations for that simulated trial field is $n$.

### EONR prediction

Root-mean-square error (RMSE) of EONR prediction for a given simulation round is:

$$
\begin{aligned}
RMSE_{EONR} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (\hat{EONR}_i - EONR_i)^2}
\end{aligned}
$$
where $EONR_i$ is the true economically optimal nitrogen rate of location $i$, and $\hat{EONR}_i$ is the predicted EONR for location $i$ by a certain model. The total number of locations for that simulated trial field is $n$.

## Profit performances

$$
\begin{aligned}
\pi_i = p_{corn} f(\hat{EONR}_i) - p_N N_i - C
\end{aligned}
$$
where $f()$ is the true yield response function set by the simulation.

The field-level profit is measured as:

$$
\begin{aligned}
\pi = {\frac{1}{n} \sum_{i=1}^{n} (\pi_i - \pi_i^{*})}
\end{aligned}
$$
where $\pi_i^{*}$ is the true maximum profit of location $i$:

$$
\begin{aligned}
\pi_i^{*} = p_{corn} f(EONR_i) - p_N N_i - C
\end{aligned}
$$
It is a relative profit measure compared the true maximum. So $\pi$ is always negative.


# Results and Discussions

## EONR prediction

The performances of machine learning and traditional regression models from 1,000 simulations were compared in Figure \@ref(fig:comb-boxplot-all). Three performance measurements: (1) out-of-sample yield prediction, (2) out-of-sample EONR prediction, and (3) profit resultant from the predicted EONR.

Table of winner counts.

Look at the large field (37.3 ha) scenario in panel (A) of Figure \@ref(fig:comb-boxplot-all). 

- Indeed, the simulation results showed that machine learning models have better yield predictions than traditional regression models. On average, the out-of-sample predicted yields' RMSE of RF (`r mean_data[field_size=="37.3 ha"&model=="RF", rmse_yield] %>% round(2)` kg ha$^{-1}$) and BRF (`r mean_data[field_size=="37.3 ha"&model=="BRF", rmse_yield] %>% round(2)` kg ha$^{-1}$) models were significantly smaller than that of OLS (`r mean_data[field_size=="37.3 ha"&model=="OLS", rmse_yield] %>% round(2)` kg ha$^{-1}$) or SER (`r mean_data[field_size=="37.3 ha"&model=="SER", rmse_yield] %>% round(2)` kg ha$^{-1}$) model. Those results are consistent with existing literature (**citations**).
- However, the better yield prediction of machine learning models does not translate into better EONR prediction. The average RMSE of out-of-sample predicted EONR of RF (`r mean_data[field_size=="37.3 ha"&model=="RF", rmse_eonr] %>% round(2)` kg ha$^{-1}$) was much larger than that of OLS (`r mean_data[field_size=="37.3 ha"&model=="OLS", rmse_eonr] %>% round(2)` kg ha$^{-1}$) or SER (`r mean_data[field_size=="37.3 ha"&model=="SER", rmse_eonr] %>% round(2)` kg ha$^{-1}$) model. BRF model's EONR prediction (RMSE `r mean_data[field_size=="37.3 ha"&model=="BRF", rmse_eonr] %>% round(2)` kg ha$^{-1}$) was better than RF model, which was similar to OLS model, but was still significantly worse than SER model. Those results showed that, despite machine learning models have better yield prediction, their EONR prediction is worse than traditional regression models.
- Ultimately, the worse EONR prediction of machine learning models resulted in lower production profit compared to the traditional regression models. The 1,000-simulation average profit of RF ($\$$`r mean_data[field_size=="37.3 ha"&model=="RF", profit] %>% round(2)` ha$^{-1}$) or BRF ($\$$`r mean_data[field_size=="37.3 ha"&model=="BRF", profit] %>% round(2)` ha$^{-1}$) model is significantly lower than that of OLS ($\$$`r mean_data[field_size=="37.3 ha"&model=="OLS", profit] %>% round(2)` ha$^{-1}$) or SER ($\$$`r mean_data[field_size=="37.3 ha"&model=="SER", profit] %>% round(2)` ha$^{-1}$) model.

## RF model is bad

- Within the machine learning models, the RF model performs especially poor in EONR prediction. Its EONR prediction RMSE was much larger than BRF model, and its associated profit was extremely low. 
- Even if we "cheat" and feed RF model with the best possible data (the true yield response parameters), its EONR prediction (RMSE `r mean_data[field_size=="37.3 ha"&model=="RF_b", rmse_eonr] %>% round(2)` kg ha$^{-1}$) and profit performance ($\$$`r mean_data[field_size=="37.3 ha"&model=="RF_b", profit] %>% round(2)` ha$^{-1}$) were still slightly worse than BRF model ($\$$`r mean_data[field_size=="37.3 ha"&model=="BRF", profit] %>% round(2)` ha$^{-1}$) with observed data. 
- Note that RF is currently a very popular machine learning method used by many agricultural studies. Our simulation results showed that although RF may be OK for yield prediction, it is terrible in EONR prediction, and will cause big economic loss if using it in decision making. Even after spending great efforts (and costs) to obtain the perfect information, using RF model still won't achieve good economic performance.

## Field sizes

Figure \@ref(fig:comb-boxplot-all) panels (B) and (C) showed the simulation results for medium (18.7 ha) and small (9.3 ha) fields.

- The result pattern of model performances was generally robust to field sizes. For any sized field, the machine learning models still have better yield predictions while worse economic performances than traditional regression models. 
- But we do notice that machine learning models' economic performances catch up when field size decreases. Especially, BRF model outperformed OLS model in EONR prediction and profit performance in small and medium fields. Although BRF model still cannot win SER in profit performance, its profit gap between SER reduced from $\$$`r (mean_data[field_size=="37.3 ha"&model=="SER", profit] - mean_data[field_size=="37.3 ha"&model=="BRF", profit]) %>% round(2)` ha$^{-1}$ in large field to $\$$`r (mean_data[field_size=="18.7 ha"&model=="SER", profit] - mean_data[field_size=="18.7 ha"&model=="BRF", profit]) %>% round(2)` ha$^{-1}$ in medium field and $\$$`r (mean_data[field_size=="9.3 ha"&model=="SER", profit] - mean_data[field_size=="9.3 ha"&model=="BRF", profit]) %>% round(2)` ha$^{-1}$ in small field.
- The results may suggest machine learning models (especially BRF) are more desirable in small fields' EONR predictions. But under the context of current farming practice, most production fields are larger than the smallest field (9.3 ha) scenario of our simulation, SER model is economically best option. 

## Illustrative explanation

- One simulation example (cherry picking, similar to the mean pattern)

- One location's yield response curves

- Treatment effects


short summary:

So, we should be cautious about the pitfall of machine learning models' good yield predicting performances. Almost all existing studies use yield prediction performance as the measure of yield estimation models. This can be very misleading and cost producers a lot when it is used in developing input management recommendations, since models with good yield prediction can have bad profit at the same time.


## OLS vs. SER: Statistical efficiency is money.

We should be more actively use SER model in yield response estimation.



## EONR prediction and profit is not perfectly one-to-one corresponding. (perhaps too much; remove this point)

Lots of agronomy studies use predicted EONR vs "true" EONR as the criteria to evaluate input recommendation algorithms. ("true" EONR is from yield responses estimated from trial data)

illustrative figure:








`r run_pagebreak()`

# Conclusions

`r run_pagebreak()`

# References

`r run_pagebreak()`

# Figures {-}

`r run_pagebreak()`

```{r comb-boxplot-all, fig.cap="The estimation performances of machine learning models (RF, RF_b, BRF) and traditional regression models (OLS, SER) over 1,000 simulations for: (A) large field (37.3 ha), (B) medium field (18.7 ha), and (C) small field (9.3 ha). The performance measurements include: (1) out-of-sample yield prediction RMSE, (2) out-of-sample EONR prediction RMSE, and (3) profit resultant from the predicted EONR.", echo=FALSE, fig.height=8.5, fig.width=7, cache=FALSE}
(comb_boxplot_large + ggtitle("(A) large field")) / (comb_boxplot_medium + ggtitle("(B) medium field")) / (comb_boxplot_small + ggtitle("(C) small field"))
```

```{r single-simu-yield, fig.cap="Example simulation, yield.", fig.width=6, fig.height=7.5, echo=FALSE, cache=FALSE}
single_simu_yield
```

```{r single-simu-EONR, fig.cap="Example simulation, EONR", fig.width=6, fig.height=7.5, echo=FALSE, cache=FALSE}
single_simu_EONR
```





# Tables {-}

```{r extreme-percent, echo=FALSE}
# knitr::kable(mean_data, format = "markdown", caption = "Summary Statistics")
```



