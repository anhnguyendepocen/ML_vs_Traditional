---
title: "Pitfall of Prediction-orienterd Machine Learning Models and Economic Value of Statistical Efficiency in On-farm Precision Experimentation"
author:
  - Taro Mieno^[University of Nebraska Lincoln, tmieno2@unl.edu], Xiaofei Li^[Mississippi State University, xiaofei.li@msstate.edu], David S. Bullock^[University of Illinois, dsbulloc@illinois.edu]
output:
  officedown::rdocx_document:
    toc: false
    toc_depth: 1
    number_sections: true
    reference_docx: "word_template.docx"
    plots:
      style: Normal
      align: center
      caption:
       style: Image Caption
       pre: "Figure "
       sep: ": "
    tables:
      style: Table
      layout: autofit
      width: 1.0
      caption:
       style: Table Caption
       pre: "Table "
       sep: ": "
# bibliography: PA.bib
# csl: american-journal-of-agricultural-economics.csl
abstract: ""
---

```{r echo = F, cache = F, include = F}
library(knitr)
library(here)

here::i_am("GitControlled/Writing/manuscript.rmd")

opts_chunk$set(
  fig.align = "center",
  fig.retina = 5,
  warning = F,
  message = F,
  cache = T,
  echo = F,
  fig.cap = TRUE
)
```

```{r cache = F, include = F}
#--- packages ---#
library(data.table)
library(tidyverse)
library(officedown)
library(officer)
library(flextable)
library(stringr)
library(sf)
library(lfe)
library(modelsummary)
library(patchwork)
library(gridExtra)
```

```{r figure_setup, cache = F}
theme_update(
  axis.title.x =
    element_text(
      size = 12, angle = 0, hjust = .5, vjust = -0.3, face = "plain"
    ),
  axis.title.y =
    element_text(
      size = 12, angle = 90, hjust = .5, vjust = .9, face = "plain"
    ),
  axis.text.x =
    element_text(
      size = 10, angle = 0, hjust = .5, vjust = 1.5, face = "plain"
    ),
  axis.text.y =
    element_text(
      size = 10, angle = 0, hjust = 1, vjust = 0, face = "plain"
    ),
  axis.ticks =
    element_line(
      size = 0.3, linetype = "solid"
    ),
  axis.ticks.length = unit(.15, "cm"),
  #--- legend ---#
  legend.text =
    element_text(
      size = 10, angle = 0, hjust = 0, vjust = 0, face = "plain"
    ),
  legend.title =
    element_text(
      size = 10, angle = 0, hjust = 0, vjust = 0, face = "plain"
    ),
  legend.key.size = unit(0.5, "cm"),
  #--- strip (for faceting) ---#
  strip.text = element_text(size = 10),
  #--- plot title ---#
  plot.title = element_text(family = "Times", face = "bold", size = 12),
  #--- margin ---#
  # plot.margin = margin(0, 0, 0, 0, "cm"),
  #--- panel ---#
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  panel.background = element_blank(),
  panel.border = element_rect(fill = NA)
)
```


```{r include = FALSE}
# /*===========================================================
#' # Prepare data and results for writing
# /*===========================================================
#* source all the functions in the Functions folder
# fs::dir_ls(here("Codes", "Functions"), full.names = TRUE) %>%
#   lapply(., function(x) source(x))

# /*----------------------------------*/
#' ##  data preparation
# /*----------------------------------*/
#' load results data
est_data <-
  readRDS(here("Shared", "Results", "est_result_ls.rds")) %>%
  rbindlist() %>%
  dplyr::select(model, perform, field_col) %>%
  unnest(perform) %>%
  data.table()
#' rename columns
est_data <- est_data %>%
  .[, .(field_col, model, sim, profit, rmse_train, rmse_cv, rmse_eonr)] %>%
  #---field size---
  .[, field_size := paste0(round(field_col * 72 * 6^2 / 10000, 1), " ha")] %>%
  .[, field_size := factor(field_size, levels = c("9.3 ha", "18.7 ha", "37.3 ha"))] %>%
  #---model name---
  .[model == "brf", model := "BRF"] %>%
  .[model == "rf", model := "RF"] %>%
  .[model == "rf_perfect", model := "RF best"] %>%
  .[model == "lm", model := "LM"] %>%
  .[model == "ser_50", model := "SER"] %>%
  .[, model := factor(model, levels = c("RF", "RF best", "BRF", "LM", "SER"))]
#' mean and sd
mean_data <- est_data %>%
  .[, .(
    profit = mean(profit) %>% round(2),
    profit_sd = sd(profit) %>% round(2),
    rmse_yield = mean(rmse_cv) %>% round(2),
    rmse_yield_sd = sd(rmse_cv) %>% round(2),
    rmse_eonr = mean(rmse_eonr) %>% round(2),
    rmse_eonr_sd = sd(rmse_eonr) %>% round(2)
  ),
  by = c("field_size", "model")
  ] %>%
  .[order(field_size, model), ]

# /*----------------------------------*/
#' ##  create figures and tables
# /*----------------------------------*/
gdata <- est_data
source(here("GitControlled", "Codes", "3_make_figures_tables.R"))
```

**Abstract**: 
 
**Keywords**: 

**Acknowledgement**: This research was supported by a USDA-NIFA-AFRI Food Security Program Coordinated Agricultural Project, titled “Using Precision Technology in On-farm Field Trials to Enable Data-Intensive Fertilizer Management,” (Accession Number 2016-68004-24769), and also by the a USDA-NRCS Conservation Innovation Grant from the On-farm Trials Program, titled “Improving the Economic and Ecological Sustainability of US Crop Production through On-Farm Precision Experimentation” (Award Number NR213A7500013G021).

`r run_pagebreak()`

# Introduction

Prediction-oriented ML methods swept the field of optimal input management as if yield prediction is the ultimate goal. RF in particular is used a lot. 

Apply ML without any clear purposes of how to use the trained models. 

+ Traditional vs ML (LM, SER better than RF and BRF)
+ Yield prediction vs EONR prediction
+ Statistical efficiency is money (SER vs LM)

The main purpose of this study is to compare the performance of prediction-oriented ML methods and traditional linear regreression approaches in terms of the profitability of estimated site-specific nitrogen recommendation. Since the true site-specific EONR and maximum profit achievable is never observable for real fields, testing the statistical and economic properties of statistical methods have to rely on simulation analysis where the data generating process is known to the researcher. We conduct MC simualtions for three different field sizes to test the economic performance of linear model OLS, linear model SER, Random Fores, and Boosted Regression Forest, where the true yield follows a quadratic plateau functional form. 

We found that while the prediction-oriented ML methods (RF and BRF) perform much better than the traditional methods (LM and SER) in predicting yield level, they perform worse than the traditional methods (LM and SER) in predicting EONR and thus in profitability of site-specific EONR recommendation. SER in particular performs the best in profitability. The economic value of its statistical efficiency over the LM approach is not negligible at <span style = "color: blue;"> Xiafei, put numbers here </span>. Our results provide a cautionary tale for those who place unsubstantiated and blind trust in prediction-oriented ML methods and apply them when the accurate estimation of ceteris paribus causal impacts of the variable of interest is warranted. 



# Methods: Monte Carlo Simulation

In our Monte Carlo simulations, we will test five estimation approches on three different sizes of fields: x ha, y ha, and x ha. In this section, we describe the data generating process, estimation approaches, and model evaluation. 

## Data Generation

Three simulated field of different sizes were created. Figure \@ref(fig:field-map) provides the map of a z-acre field as an example. The field consisted of $384$ 18.3 m $\times$ 73.2 m "plots," each of which was assigned an N fertilizer application rate. Each plot was made up of four (4-rows $\times$ 1-column) 18.3 m $\times$ 18.3 m "subplots," which were unit of analysis used in subsequent statistical analysis. Each subplot contained of a 6-rows $\times$ 6-columns grid of thirty-six 3.05 m $\times$ 3.05 m "cells." All field characteristics and yield data were generated at the cell level. 

Data were generated at the cell-level and then aggregted up to analysis-unit levle (why). Cell-levle yields were generated following the quadratic-plateau functional form as follows:

$$
\begin{aligned}
y_{i,j} = 
  \begin{cases}
  \alpha_{i,j} + \beta_{i,j} N + \gamma_{i,j} N^2 + \varepsilon_{i,j}, & N < \tau_{i,j} \\
  \eta_{i,j}, & N \geq \tau_{i,j}
  \end{cases}
\end{aligned}
$$

In this formualtion, yield increases as $N_{i,j}$ increaes until $N_{i,j}$ reaches $\tau_{i,j}$, at which yield hits the plateau, $\eta_{i,j}$. The yield level at $N_{i,j}= 0$ is $\alpha_{i,j}$. The rate at which yield increases with repsect to $N_{i,j}$ is governed by $\beta_{i,j}$ and $\gamma_{i,j}$. 

Farmers do not observe any of the parameters, but observe the decomposition of the parameters that goven the yield resopnse function. Specifically,

$$
\begin{aligned}
\alpha_{i,j} & = \alpha^1_{i,j} + \alpha^2_{i,j} \\
\tau_{i,j} & = min\big(min(\tau^{1,1}_{i,j}, \tau^{1,2}_{i,j}), min(\tau^{2,1}_{i,j}, \tau^{2,2}_{i,j})\big) \\
\eta_{i,j} & = min\big(min(\eta^{1,1}_{i,j}, \eta^{1,2}_{i,j}), min(\eta^{2,1}_{i,j}, \eta^{2,2}_{i,j})\big) 
\end{aligned}
$$

We denote the collection of covariate ($\alpha^1_{i,j}$, $\alpha^2_{i,j}$, $\tau^{1,1}_{i,j}$, $\tau^{1,2}_{i,j}$, $\tau^{2,1}_{i,j}$, $\tau^{2,2}_{i,j}$, $\eta^{1,1}_{i,j}$, $\eta^{1,2}_{i,j}$, $\eta^{2,1}_{i,j}$, $\eta^{2,2}_{i,j}$) as $X^1_{i,j}$. Note that $\alpha_{i,j}$, $\tau_{i,j}$, and $\eta_{i,j}$ (or equivalently $X^1_{i,j}$) have sufficient information to completely characterize the yield response function. This is because the coefficients $\beta_{i,j}$ and $\gamma_{i,j}$ are identified once $\alpha_{i,j}$, $\tau_{i,j}$, and $\eta_{i,j}$ are determined. These covariates are generated in a way that they are spatially correlated and also correlated with one another (Please see the codes available at <span style = "color: blue;"> gihutb account here</span>).

In addition to the covariates, two nuisance covariates that are correlated with eahc of $\alpha_{i,j}$, $\tau_{i,j}$, and $\eta_{i,j}$ are generated: $\phi^{\alpha, 1}_{i,j}$, $\phi^{\alpha, 2}_{i,j}$, $\phi^{\tau, 1}_{i,j}$, $\phi^{\tau, 2}_{i,j}$, $\phi^{\eta, 1}_{i,j}$, $\phi^{\eta, 2}_{i,j}$. We denote these variables as $X^2_{i,j}$. These variables are nuisance in the sense that they provide no additional information about the yield response functions once $X^1_{i,j}$ are included as covariates. Since they are correlated with $X^1_{i,j}$, the inclusion of $X^2_{i,j}$ would interfere with accurate identification of the $X^1_{i,j}$. We denote $X^1_{i,j}$ and $X^2_{i,j}$ collectively as $X_{i,j}$. Once the cell-level variables are generated, true economically optimal can be found by solving the profit maximization problem. This process is repeated 1000 times to create 1000 datasets. See Appendix \@ref(parameters) for maps of some of the covariates and true EONR for a single simulation round as an example. The cell level data were then aggregated up to the analysis unit level data: $\{y_i, X_i\}$.

## Estamation of yield response functions and site-specific optimal nitrogen rates

**Approach 1**: Linear Model OLS (Hereafter, LM)

The LM approach assumes a quadratic yield response function:

$$
\begin{aligned}
y_i = \beta_0 + \beta_1 \cdot N_i + \beta_2\cdot N_i^2 + N_i\cdot X_i\cdot \gamma_1 + N_i^2\cdot X_i\cdot \gamma_2 + \varepsilon
\end{aligned}
$$

where $\gamma_1$ and $\gamma_2$ are sets of interactions of $X_i$ with $N_i$, and $\varepsilon$ is the error term. The model is certainly misspecified because quadratic functions cannot perfectly represent yield response functions with a plateau (cite). It is known that the use of the quadratic functional form tends to over-estimate the true optimal nitrogen rate. However, it still approximates the underlying yield response functions quite well and is a popular functional form (cite). The _feols_ package in R was used to estimate the model (cite). 

**Approach 2**: Spatial Error Model (SER) 

The econometic model for the SER approach follows that of the LM approach except for the error term.

$$
\begin{aligned}
y_i &= \beta_0 + \beta_1 \cdot N_i + \beta_2\cdot N_i^2 + N_i\cdot X_i\cdot \gamma_1 + N_i^2\cdot X_i\cdot \gamma_2 + \varepsilon \\
\varepsilon & = \lambda W \varepsilon + \mu
\end{aligned}
$$

where $\lambda$ is scaler that reflects the degree of spatial dependence, $W$ is the user-defined weight matrix, and $\mu$ is the idiosynctaric error term that is not spatially correlated. Estimation via the spatial error model takes into account the spatial dependency of the error term and thus statistically more  efficient than the LM approach. The _spatialreg_ package in R was used to estimate the model (cite).  

**Approach 3**: Random Forest (RF)

Unlike the LM and SER approaches, it does not assume any particular functional relationships between the dependent vairable and the covaraites. Random Forest consists of ensembles of trees. In each tree, the train data is split into a number of leaves based on the covirate values and all the observations belonging to the same leaf share the same yield estimate. Unlike a single classification and regression tree (CART), RF tends to avoid overfitting thanks to the averaging of estimates from the individual trees. The RF approach uses all the variables $(X_{i})$ as covariates.

**Approach 4**: best Random Forest (RF$_{best}$)

The RF$_{best}$ approach uses $\alpha$, $\beta$, and $\gamma$ directly to give a comparative advantage to RF relative to the other methods, instead of $(X_{i})$. 

**Approach 5**: Boosted Regression Forest (BRF)

While RF builds individual trees completely independent of one another, BRF build trees in a way that focuses relatively more on imroving the parts of the data that are not well explained in the previous sequence of trees. Consequently, BRF tends to perform better than RF in predicting yield. However, its use in the context of site-specific input management is limited compared to RF at the moment. The BRF approach uses all the covaraites in $X$ like the LM, SER, and RF approaches. The _grf_ package in R was used to run the RF, RF$_{best}$, and BRF estimations (cite). Hyperparameters were tuned using cross-validation.  

For all the approches, once the yield response functions are estimated, site-specific EONR are calculated by numerically solving profit maximization problems at the cell level. Corn and nitrogen prices are assumed to be <span style = "color: blue;"> Xiaofei, put numbers here </span>. The codes to implement the MC simulations are publicly accessible at <span style = "color: blue;"> github account</span>. 

## Performance Measurement

For a given simulation round, we calculate root mean squared error (RMSE) of yield and EONR predictions and profit deficit for each approach. Profit deficit is defined as the true maximum profit less the profit obtained by following the estimated site-specifc EONR. To calculate these measures for a given simulation round, the dataset from another simulation round is used as the test dataset. This practice works as datasets across simulation rounds are created independently while following the same data generating process.


### Yield prediction

Root-mean-square error (RMSE) of yield prediction for a given simulation round is:

$$
\begin{aligned}
RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)^2}
\end{aligned}
$$
where $y_i$ is the true yield of location $i$ from applying the trial N rate, and $\hat{y}_i$ is the predicted yield of the same location by a certain model. The total number of locations for that simulated trial field is $n$.

### EONR prediction

Root-mean-square error (RMSE) of EONR prediction for a given simulation round is:

$$
\begin{aligned}
RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (\hat{EONR}_i - EONR_i)^2}
\end{aligned}
$$
where $EONR_i$ is the true economically optimal nitrogen rate of location $i$, and $\hat{EONR}_i$ is the predicted EONR for location $i$ by a certain model. The total number of locations for that simulated trial field is $n$.

### Profit

The production profit of location $i$ by applying the estimated site-specific EONR is:

$$
\begin{aligned}
\pi_i = p_{corn} f(\hat{EONR}_i) - p_N N_i - C
\end{aligned}
$$
where $f()$ is the true yield response function set by the simulation.

The field-level profit is measured as:

$$
\begin{aligned}
\pi = {\frac{1}{n} \sum_{i=1}^{n} (\pi_i - \pi_i^{*})}
\end{aligned}
$$
where $\pi_i^{*}$ is the true maximum profit of location $i$:

$$
\begin{aligned}
\pi_i^{*} = p_{corn} f(EONR_i) - p_N N_i - C
\end{aligned}
$$
It is a relative profit measure compared the true maximum. So $\pi$ is always negative.


# Results and Discussions

## Main point 1:
Despite machine learning models perform better in yield predicting, their EONR prediction is poor.

The performances of different models in out-of-sample yield prediction, EONR prediction, and EONR profitability over 1,000 simulations are displayed in Figure \@ref(fig:comb-boxplot-large) for the large trial field (37.3 ha) scenario. 

- Indeed, the simulation results showed the machine learning models perform better than traditional regression models in yield predicting. On average, the predicted yields' RMSE of RF (`r mean_data[field_size=="37.3 ha"&model=="RF", rmse_yield] %>% round(2)` kg ha$^{-1}$) and BRF (`r mean_data[field_size=="37.3 ha"&model=="BRF", rmse_yield] %>% round(2)` kg ha$^{-1}$) models are significantly smaller than that of the LM (`r mean_data[field_size=="37.3 ha"&model=="LM", rmse_yield] %>% round(2)` kg ha$^{-1}$) or SER (`r mean_data[field_size=="37.3 ha"&model=="SER", rmse_yield] %>% round(2)` kg ha$^{-1}$) model. Those findings are consistent with existing literature (**citations**).
- However, the better yield prediction of machine learning models does not necessarily translate into better EONR prediction. The predicted EONR's RMSE of the RF model (`r mean_data[field_size=="37.3 ha"&model=="RF", rmse_eonr] %>% round(2)` kg ha$^{-1}$) is much larger than the LM (`r mean_data[field_size=="37.3 ha"&model=="LM", rmse_eonr] %>% round(2)` kg ha$^{-1}$) or SER (`r mean_data[field_size=="37.3 ha"&model=="SER", rmse_eonr] %>% round(2)` kg ha$^{-1}$) model, meaning the RF model generates much inaccurate EONR predictions, despite its more accurate yield predictions, than LM or SER model. BRF model's EONR prediction is much better than RF model, whose RMSE (`r mean_data[field_size=="37.3 ha"&model=="BRF", rmse_eonr] %>% round(2)` kg ha$^{-1}$) is only slightly smaller than the LM model. But it is still significantly larger than the SER model.
- Finally, the less accurate EONR predictions by machine learning models lead to lower profits. The average profit of RF model ($\$$`r mean_data[field_size=="37.3 ha"&model=="RF", profit] %>% round(2)` ha$^{-1}$) is extremely low. The BRF model profit ($\$$`r mean_data[field_size=="37.3 ha"&model=="BRF", profit] %>% round(2)` ha$^{-1}$) is much higher than RF, but still significantly lower than the basic LM model ($\$$`r mean_data[field_size=="37.3 ha"&model=="LM", profit] %>% round(2)` ha$^{-1}$). The SER model profit is as high as $\$$`r mean_data[field_size=="37.3 ha"&model=="SER", profit] %>% round(2)` ha$^{-1}$.

So, we should be cautious about the pitfall of machine learning models' good yield predicting performances. Almost all existing studies use yield prediction performance as the measure of yield estimation models. This can be very misleading and cost producers a lot when it is used in developing input management recommendations, since models with good yield prediction can have bad profit at the same time.

## Main point 2:
The model performances are generally robust to field sizes. But we also found that machine learning models' performances are less affected by field size reduction.

The simulation results for medium (18.7 ha) and small (9.3 ha) trial field scenarios are displayed in Figure \@ref(fig:comb-boxplot-medium) and \@ref(fig:comb-boxplot-small).

- The RF model still has better yield prediction while worse EONR prediction and profit than the LM and SER models.
- The BRF model outperforms LM model in EONR prediction and profit in medium and small trial fields. 
- Though the BRF model still cannot beat SER model in smaller fields, the gap between BRF and SER shrink as field size reduces. For the small field (9.3 ha), BRF's predicted EONR RMSE (`r mean_data[field_size=="9.3 ha"&model=="BRF", rmse_eonr] %>% round(2)` kg ha$^{-1}$) is almost as small as that of the SER model (`r mean_data[field_size=="9.3 ha"&model=="SER", rmse_eonr] %>% round(2)` kg ha$^{-1}$), and the profit gap between the BRF model (`r mean_data[field_size=="9.3 ha"&model=="BRF", profit] %>% round(2)` kg ha$^{-1}$) and the SER model (`r mean_data[field_size=="9.3 ha"&model=="BRF", profit] %>% round(2)` kg ha$^{-1}$) reduces to only about two thirds of the large field (37.3 ha) scenario.

So, the better economic performances of traditional regression models require larger trial field sizes. Machine learning models' performances are less sensitive to field sizes. At the current prevailing on-farm experimental field sizes, traditional regression models perform well. But if the trial fields are really small, machine learning models (especially BRF) will be more suitable.

## Main point 3:
EONR prediction and profit is not perfectly one-on-one corresponding.

Lots of agronomy studies use predicted EONR vs "true" EONR as the criteria to evaluate input recommendation algorithms. ("true" EONR is from yield responses estimated from trial data)


## Main point 4:
RF model is bad.

- Even if we "cheat" and feed RF model with the best data, its profit is still only $\$$`r mean_data[field_size=="37.3 ha"&model=="RF best", profit] %>% round(2)` ha$^{-1}$ 
If we estimate RF model with the best data, its RMSE will be further smaller (`r mean_data[field_size=="37.3 ha"&model=="RF best", rmse_yield] %>% round(2)` kg ha$^{-1}$).

## Main point 5:
LM vs. SER: Statistical efficiency is money.

We should be more actively use SER model in yield response estimation.



`r run_pagebreak()`

# Conclusions

`r run_pagebreak()`

# References


# Figures {-}

```{r comb-boxplot-large, fig.cap="The performances of different models, large field.", echo=FALSE, fig.width=6}
comb_boxplot_large
```

```{r comb-boxplot-medium, fig.cap="The performances of different models, medium field.", echo=FALSE, fig.width=6}
comb_boxplot_medium
```

```{r comb-boxplot-small, fig.cap="The performances of different models, small field.", echo=FALSE, fig.width=6}
comb_boxplot_small
```


# Tables {-}

```{r extreme-percent, echo=FALSE}
# knitr::kable(mean_data, format = "markdown", caption = "Summary Statistics")
```



