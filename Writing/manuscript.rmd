---
title: "Pitfall of Prediction-orienterd Machine Learning Methods and Economic Value of Statistical Efficiency in On-farm Precision Experimentation"
author:
  - Taro Mieno^[University of Nebraska Lincoln, tmieno2@unl.edu], Xiaofei Li^[Mississippi State University, xiaofei.li@msstate.edu], David S. Bullock^[University of Illinois, dsbulloc@illinois.edu]
output:
  officedown::rdocx_document:
    toc: false
    toc_depth: 1
    number_sections: true
    reference_docx: "word_template.docx"
    plots:
      style: Normal
      align: center
      caption:
       style: Image Caption
       pre: "Figure "
       sep: ": "
    tables:
      style: Table
      layout: autofit
      width: 1.0
      caption:
       style: Table Caption
       pre: "Table "
       sep: ": "
# bibliography: PA.bib
# csl: american-journal-of-agricultural-economics.csl
abstract: ""
---

```{r echo = F, cache = F, include = F}
library(knitr)
library(here)

here::i_am("GitControlled/Writing/manuscript.rmd")

opts_chunk$set(
  fig.align = "center",
  fig.retina = 5,
  warning = F,
  message = F,
  cache = T,
  echo = F,
  fig.cap = TRUE
)
```

```{r cache = F, include = F}
#--- packages ---#
library(data.table)
library(tidyverse)
library(officedown)
library(officer)
library(flextable)
library(stringr)
library(sf)
library(lfe)
library(modelsummary)
library(patchwork)
library(gridExtra)
```

```{r figure_setup, cache = F}
theme_update(
  axis.title.x =
    element_text(
      size = 12, angle = 0, hjust = .5, vjust = -0.3, face = "plain"
    ),
  axis.title.y =
    element_text(
      size = 12, angle = 90, hjust = .5, vjust = .9, face = "plain"
    ),
  axis.text.x =
    element_text(
      size = 10, angle = 0, hjust = .5, vjust = 1.5, face = "plain"
    ),
  axis.text.y =
    element_text(
      size = 10, angle = 0, hjust = 1, vjust = 0, face = "plain"
    ),
  axis.ticks =
    element_line(
      size = 0.3, linetype = "solid"
    ),
  axis.ticks.length = unit(.15, "cm"),
  #--- legend ---#
  legend.text =
    element_text(
      size = 10, angle = 0, hjust = 0, vjust = 0, face = "plain"
    ),
  legend.title =
    element_text(
      size = 10, angle = 0, hjust = 0, vjust = 0, face = "plain"
    ),
  legend.key.size = unit(0.5, "cm"),
  #--- strip (for faceting) ---#
  strip.text = element_text(size = 10),
  #--- plot title ---#
  plot.title = element_text(family = "Times", face = "bold", size = 12),
  #--- margin ---#
  # plot.margin = margin(0, 0, 0, 0, "cm"),
  #--- panel ---#
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  panel.background = element_blank(),
  panel.border = element_rect(fill = NA)
)
```


```{r include = FALSE}
# /*===========================================================
#' # Prepare data and results for writing
# /*===========================================================
#* source all the functions in the Functions folder
# fs::dir_ls(here("Codes", "Functions"), full.names = TRUE) %>%
#   lapply(., function(x) source(x))

# /*----------------------------------*/
#' ##  data preparation
# /*----------------------------------*/
#' load results data
est_data <-
  readRDS(here("Shared", "Results", "est_result_ls.rds")) %>%
  rbindlist() %>%
  dplyr::select(model, perform, field_col) %>%
  unnest(perform) %>%
  data.table()
#' rename columns
est_data <- est_data %>%
  .[, .(field_col, model, sim, profit, rmse_train, rmse_cv, rmse_eonr)] %>%
  #---field size---
  .[, field_size := paste0(round(field_col * 72 * 6^2 / 10000, 1), " ha")] %>%
  .[, field_size := factor(field_size, levels = c("9.3 ha", "18.7 ha", "37.3 ha"))] %>%
  #---model name---
  .[model == "brf", model := "BRF"] %>%
  .[model == "rf", model := "RF"] %>%
  .[model == "rf_perfect", model := "RF_b"] %>%
  .[model == "lm", model := "OLS"] %>%
  .[model == "ser_50", model := "SER"] %>%
  .[, model := factor(model, levels = c("RF", "RF_b", "BRF", "OLS", "SER"))]
#' mean and sd
mean_data <- est_data %>%
  .[, .(
    profit = mean(profit) %>% round(2),
    profit_sd = sd(profit) %>% round(2),
    rmse_yield = mean(rmse_cv) %>% round(2),
    rmse_yield_sd = sd(rmse_cv) %>% round(2),
    rmse_eonr = mean(rmse_eonr) %>% round(2),
    rmse_eonr_sd = sd(rmse_eonr) %>% round(2)
  ),
  by = c("field_size", "model")
  ] %>%
  .[order(field_size, model), ]
#' load illustration data (single simulation)
illus_data <-
  readRDS(here("Shared", "Results", "illus_data.rds"))

# /*----------------------------------*/
#' ##  create figures and tables
# /*----------------------------------*/
source(here("GitControlled", "Codes", "3_make_figures_tables.R"))
```

**Abstract**: 
 
**Keywords**: 

**Acknowledgement**: This research was supported by a USDA-NIFA-AFRI Food Security Program Coordinated Agricultural Project, titled “Using Precision Technology in On-farm Field Trials to Enable Data-Intensive Fertilizer Management,” (Accession Number 2016-68004-24769), and also by the a USDA-NRCS Conservation Innovation Grant from the On-farm Trials Program, titled “Improving the Economic and Ecological Sustainability of US Crop Production through On-Farm Precision Experimentation” (Award Number NR213A7500013G021).

`r run_pagebreak()`

# Introduction

Prediction-oriented ML methods swept the field of optimal input management as if yield prediction is the ultimate goal. RF in particular is used a lot. 

Apply ML without any clear purposes of how to use the trained models. 

+ Traditional vs ML (OLS, SER better than RF and BRF)
+ Yield prediction vs EONR prediction
+ Statistical efficiency is money (SER vs OLS)

The main purpose of this study is to compare the performance of prediction-oriented ML methods and traditional linear regression approaches in terms of the profitability of estimated site-specific nitrogen recommendation. Since the true site-specific EONR and maximum profit achievable is never observable for real fields, testing the statistical and economic properties of statistical methods have to rely on simulation analysis where the data generating process is known to the researcher. We conduct MC simulations for three different field sizes to test the economic performance of linear model OLS, linear model SER, Random Fores, and Boosted Regression Forest, where the true yield follows a quadratic plateau functional form. 

We found that while the prediction-oriented ML methods (RF and BRF) perform much better than the traditional methods (OLS and SER) in predicting yield level, they perform worse than the traditional methods (OLS and SER) in predicting EONR and thus in profitability of site-specific EONR recommendation. SER in particular performs the best in profitability. The economic value of its statistical efficiency over the OLS approach is not negligible at <span style = "color: blue;"> Xiafei, put numbers here </span>. Our results provide a cautionary tale for those who place unsubstantiated and blind trust in prediction-oriented ML methods and apply them when the accurate estimation of ceteris paribus causal impacts of the variable of interest is warranted. 

# Methods: Monte Carlo Simulation

In our Monte Carlo simulations, we will test five estimation approaches on three different sizes of fields: x ha, y ha, and x ha. In this section, we describe the data generating process, estimation approaches, and model evaluation. 

## Data Generation

Three simulated field of different sizes were created. Figure \@ref(fig:field-map) provides the map of a z-acre field as an example. The field consisted of $384$ 18.3 m $\times$ 73.2 m "plots," each of which was assigned an N fertilizer application rate. Each plot was made up of four (4-rows $\times$ 1-column) 18.3 m $\times$ 18.3 m "subplots," which were unit of analysis used in subsequent statistical analysis. Each subplot contained of a 6-rows $\times$ 6-columns grid of thirty-six 3.05 m $\times$ 3.05 m "cells." All field characteristics and yield data were generated at the cell level. 

Data were generated at the cell-level and then aggregated up to analysis-unit level (why). Cell-level yields were generated following the quadratic-plateau functional form as follows:

$$
\begin{aligned}
y_{i,j} = 
  \begin{cases}
  \alpha_{i,j} + \beta_{i,j} N + \gamma_{i,j} N^2 + \varepsilon_{i,j}, & N < \tau_{i,j} \\
  \eta_{i,j} + \varepsilon_{i,j}, & N \geq \tau_{i,j}
  \end{cases}
\end{aligned}
$$

In this formulation, yield increases as $N_{i,j}$ increase until $N_{i,j}$ reaches $\tau_{i,j}$, at which yield hits the plateau, $\eta_{i,j}$. The yield level at $N_{i,j}= 0$ is $\alpha_{i,j}$. The rate at which yield increases with respect to $N_{i,j}$ is governed by $\beta_{i,j}$ and $\gamma_{i,j}$. 

Farmers do not observe any of the parameters, but observe the decomposition of the parameters that given the yield response function. Specifically,

$$
\begin{aligned}
\alpha_{i,j} & = \alpha^1_{i,j} + \alpha^2_{i,j} \\
\tau_{i,j} & = min\big(min(\tau^{1,1}_{i,j}, \tau^{1,2}_{i,j}), min(\tau^{2,1}_{i,j}, \tau^{2,2}_{i,j})\big) \\
\eta_{i,j} & = min\big(min(\eta^{1,1}_{i,j}, \eta^{1,2}_{i,j}), min(\eta^{2,1}_{i,j}, \eta^{2,2}_{i,j})\big) 
\end{aligned}
$$

We denote the collection of covariate ($\alpha^1_{i,j}$, $\alpha^2_{i,j}$, $\tau^{1,1}_{i,j}$, $\tau^{1,2}_{i,j}$, $\tau^{2,1}_{i,j}$, $\tau^{2,2}_{i,j}$, $\eta^{1,1}_{i,j}$, $\eta^{1,2}_{i,j}$, $\eta^{2,1}_{i,j}$, $\eta^{2,2}_{i,j}$) as $X^1_{i,j}$. Note that $\alpha_{i,j}$, $\tau_{i,j}$, and $\eta_{i,j}$ (or equivalently $X^1_{i,j}$) have sufficient information to completely characterize the yield response function. This is because the coefficients $\beta_{i,j}$ and $\gamma_{i,j}$ are identified once $\alpha_{i,j}$, $\tau_{i,j}$, and $\eta_{i,j}$ are determined. These covariates are generated in a way that they are spatially correlated and also correlated with one another (Please see the codes available at <span style = "color: blue;"> gihutb account here</span>).

In addition to the covariates, two nuisance covariates that are correlated with each of $\alpha_{i,j}$, $\tau_{i,j}$, and $\eta_{i,j}$ are generated: $\phi^{\alpha, 1}_{i,j}$, $\phi^{\alpha, 2}_{i,j}$, $\phi^{\tau, 1}_{i,j}$, $\phi^{\tau, 2}_{i,j}$, $\phi^{\eta, 1}_{i,j}$, $\phi^{\eta, 2}_{i,j}$. We denote these variables as $X^2_{i,j}$. These variables are nuisance in the sense that they provide no additional information about the yield response functions once $X^1_{i,j}$ are included as covariates. Since they are correlated with $X^1_{i,j}$, the inclusion of $X^2_{i,j}$ would interfere with accurate identification of the $X^1_{i,j}$. We denote $X^1_{i,j}$ and $X^2_{i,j}$ collectively as $X_{i,j}$. Once the cell-level variables are generated, true economically optimal can be found by solving the profit maximization problem. This process is repeated 1000 times to create 1000 datasets. See Appendix \@ref(parameters) for maps of some of the covariates and true EONR for a single simulation round as an example. The cell level data were then aggregated up to the analysis unit level data: $\{y_i, X_i\}$.

## Estamation of yield response functions and site-specific optimal nitrogen rates

**Approach 1**: Linear Model OLS (Hereafter, OLS)

The OLS approach assumes a quadratic yield response function:

$$
\begin{aligned}
y_i = \beta_0 + \beta_1 \cdot N_i + \beta_2\cdot N_i^2 + N_i\cdot X_i\cdot \gamma_1 + N_i^2\cdot X_i\cdot \gamma_2 + \varepsilon
\end{aligned}
$$

where $\gamma_1$ and $\gamma_2$ are sets of interactions of $X_i$ with $N_i$, and $\varepsilon$ is the error term. The model is certainly misspecified because quadratic functions cannot perfectly represent yield response functions with a plateau (cite). It is known that the use of the quadratic functional form tends to over-estimate the true optimal nitrogen rate. However, it still approximates the underlying yield response functions quite well and is a popular functional form (cite). The _feols_ package in R was used to estimate the model (cite). 

**Approach 2**: Spatial Error Model (SER) 

The econometic model for the SER approach follows that of the OLS approach except for the error term.

$$
\begin{aligned}
y_i &= \beta_0 + \beta_1 \cdot N_i + \beta_2\cdot N_i^2 + N_i\cdot X_i\cdot \gamma_1 + N_i^2\cdot X_i\cdot \gamma_2 + \varepsilon \\
\varepsilon & = \lambda W \varepsilon + \mu
\end{aligned}
$$

where $\lambda$ is scaler that reflects the degree of spatial dependence, $W$ is the user-defined weight matrix, and $\mu$ is the idiosynctaric error term that is not spatially correlated. Estimation via the spatial error model takes into account the spatial dependency of the error term and thus statistically more  efficient than the OLS approach. The _spatialreg_ package in R was used to estimate the model (cite).  

**Approach 3**: Random Forest (RF)

Unlike the OLS and SER approaches, it does not assume any particular functional relationships between the dependent vairable and the covaraites. Random Forest consists of ensembles of trees. In each tree, the train data is split into a number of leaves based on the covirate values and all the observations belonging to the same leaf share the same yield estimate. Unlike a single classification and regression tree (CART), RF tends to avoid overfitting thanks to the averaging of estimates from the individual trees. The RF approach uses all the variables $(X_{i})$ as covariates.

**Approach 4**: best Random Forest (RF$_{best}$)

The RF$_{best}$ approach uses $\alpha$, $\beta$, and $\gamma$ directly to give a comparative advantage to RF relative to the other methods, instead of $(X_{i})$. 

**Approach 5**: Boosted Regression Forest (BRF)

While RF builds individual trees completely independent of one another, BRF build trees in a way that focuses relatively more on imroving the parts of the data that are not well explained in the previous sequence of trees. Consequently, BRF tends to perform better than RF in predicting yield. However, its use in the context of site-specific input management is limited compared to RF at the moment. The BRF approach uses all the covaraites in $X$ like the OLS, SER, and RF approaches. The _grf_ package in R was used to run the RF, RF$_{best}$, and BRF estimations (cite). Hyperparameters were tuned using cross-validation.  

For all the approches, once the yield response functions are estimated, site-specific EONR are calculated by numerically solving profit maximization problems at the cell level. Corn and nitrogen prices are assumed to be <span style = "color: blue;"> Xiaofei, put numbers here </span>. The codes to implement the MC simulations are publicly accessible at <span style = "color: blue;"> github account</span>. 

## Performance Measurement

For a given simulation round, we calculate root mean squared error (RMSE) of yield and EONR predictions and profit deficit for each approach. Profit deficit is defined as the true maximum profit less the profit obtained by following the estimated site-specifc EONR. To calculate these measures for a given simulation round, the dataset from another simulation round is used as the test dataset. This practice works as datasets across simulation rounds are created independently while following the same data generating process.


### Yield prediction

Root-mean-square error (RMSE) of yield prediction for a given simulation round is:

$$
\begin{aligned}
RMSE_{y} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)^2}
\end{aligned}
$$
where $y_i$ is the true yield of location $i$ from applying the trial N rate, and $\hat{y}_i$ is the predicted yield of the same location by a certain model. The total number of locations for that simulated trial field is $n$.

### EONR prediction

Root-mean-square error (RMSE) of EONR prediction for a given simulation round is:

$$
\begin{aligned}
RMSE_{EONR} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (\hat{EONR}_i - EONR_i)^2}
\end{aligned}
$$
where $EONR_i$ is the true economically optimal nitrogen rate of location $i$, and $\hat{EONR}_i$ is the predicted EONR for location $i$ by a certain model. The total number of locations for that simulated trial field is $n$.

## Profit performances

$$
\begin{aligned}
\pi_i = p_{corn} f(\hat{EONR}_i) - p_N N_i - C
\end{aligned}
$$
where $f()$ is the true yield response function set by the simulation.

The field-level profit is measured as:

$$
\begin{aligned}
\pi = {\frac{1}{n} \sum_{i=1}^{n} (\pi_i - \pi_i^{*})}
\end{aligned}
$$
where $\pi_i^{*}$ is the true maximum profit of location $i$:

$$
\begin{aligned}
\pi_i^{*} = p_{corn} f(EONR_i) - p_N N_i - C
\end{aligned}
$$
It is a relative profit measure compared the true maximum. So $\pi$ is always negative.


# Results and Discussions

## EONR prediction

The performances of machine learning and traditional regression models from 1,000 simulations were compared in Figure \@ref(fig:comb-boxplot-all). Three performance measurements were presented: (1) out-of-sample yield prediction, (2) out-of-sample EONR prediction, and (3) profit resultant from the predicted EONR.

First look at the large field (37.3 ha) scenario as shown in panel (A) of Figure \@ref(fig:comb-boxplot-all). 

Machine learning models showed better yield prediction performances than traditional regression models. On average, the out-of-sample predicted yields' RMSE of RF (`r mean_data[field_size=="37.3 ha"&model=="RF", rmse_yield] %>% round(2)` kg ha$^{-1}$) and BRF (`r mean_data[field_size=="37.3 ha"&model=="BRF", rmse_yield] %>% round(2)` kg ha$^{-1}$) models were significantly smaller than that of OLS (`r mean_data[field_size=="37.3 ha"&model=="OLS", rmse_yield] %>% round(2)` kg ha$^{-1}$) or SER (`r mean_data[field_size=="37.3 ha"&model=="SER", rmse_yield] %>% round(2)` kg ha$^{-1}$) model. Those results are consistent with existing literature (**citations**). However, the better yield predictions from the machine learning models did not translate into better EONR predictions for them. The average RMSE of out-of-sample predicted EONR of RF model (`r mean_data[field_size=="37.3 ha"&model=="RF", rmse_eonr] %>% round(2)` kg ha$^{-1}$) was much larger than that of OLS (`r mean_data[field_size=="37.3 ha"&model=="OLS", rmse_eonr] %>% round(2)` kg ha$^{-1}$) or SER (`r mean_data[field_size=="37.3 ha"&model=="SER", rmse_eonr] %>% round(2)` kg ha$^{-1}$) model. BRF model's EONR prediction (RMSE `r mean_data[field_size=="37.3 ha"&model=="BRF", rmse_eonr] %>% round(2)` kg ha$^{-1}$) was better than RF model, and was similar to OLS model, but still significantly worse than SER model. As expected, a similar pattern of relative performance of the models are observed in terms of the profitability of site-specific EONR recomendations. The average profit of RF ($\$$`r mean_data[field_size=="37.3 ha"&model=="RF", profit] %>% round(2)` ha$^{-1}$) or BRF ($\$$`r mean_data[field_size=="37.3 ha"&model=="BRF", profit] %>% round(2)` ha$^{-1}$) model was significantly lower than that of OLS ($\$$`r mean_data[field_size=="37.3 ha"&model=="OLS", profit] %>% round(2)` ha$^{-1}$) or SER ($\$$`r mean_data[field_size=="37.3 ha"&model=="SER", profit] %>% round(2)` ha$^{-1}$) model. These results clearly demonstrate that better yield prediction does not necessarily lead to better site-specific EONR prediction and thus more profitable site-specific input recommendations. This results is a cautionary for us to not select models and methods based on their yield prediction capabilities.  
 
It is noteworthy that RF model performed especially poor in EONR prediction because RF is currently a very popular machine learning method in yield response function estimation. Its EONR prediction RMSE was much larger than BRF model, and its associated profit was extremely low (as shown in Figure \@ref(fig:comb-boxplot-all) panel (A)). Even when the RF model is fed with the true yield response parameters ($\alpha$, $\tau$, $\eta$) directly, its EONR profit ($\$$`r mean_data[field_size=="37.3 ha"&model=="RF_b", profit] %>% round(2)` ha$^{-1}$) was still slightly lower than BRF model ($\$$`r mean_data[field_size=="37.3 ha"&model=="BRF", profit] %>% round(2)` ha$^{-1}$) that was estimated using all the observed variables. Our simulation results showed that BRF is simply a superior model than RF both in terms yield prediction and EONR predictions. Given BRF is just as easy to implement in popular statistical software like R and python, it seems hard to justify the use of RF any longer at least in the context of site-speific yield response function estimation.

Finally, while the ML methods perform worse than LM and SER on average, it does not mean they perform worse in terms of profitability in every single simualtion round. Figure \@ref() shows the percentage each model performed the best in yield prediciton (panel a), EONR prediciton (panel b), and profitability (panel c). 


## Insights into the divergence in yield and EONR prediction performance

It may sound counterintuitive that better yield prediction does not necessarily lead to better EONR prediction and economic performance. Here, we present an illustrative example to provide some explanations for this divergence between yield and EONR predictions. 

Figure \@ref(fig:single-simu-illustrate) shows the predicted versus true yield (panel A) and EONR (panel B) of the 1,440 locations ($aunit$) from a single simulation round for the large field case. The RMSE measurements associated with each model's results for this specific simulation were displayed in the figure as well. Though the machine learning models (RF, RF_b, and BRF) generated well-predicted yields such that the plotted points were well distributed along the 45 degree line, their predicted EONR were not continuous but fell into several discrete values. That results were to a large extent caused by the discrete data of five nitrogen trial rates. But that is how the on-farm experimental data generally look like in practice. On the other hand, the SER model's predicted EONR were much better aligned the 45 degree line, despite its predicted yields were not as good as the machine learning models. The OLS model's EONR predictions are also continuous, but with too big dispersion. 

Figure \@ref(fig:yield-curves) illustrates the estimated yield response curves by different models at a specific location ($aunit$). The circle point denoted the trial N rate and true (deterministic part of) yield. It shows that the machine learning models' predicted yields were closer to the true yield. However, the shape of yield response curves predicted by machine learning models were much less accurate compared to that of SER. On the other hand, SER model's predicted yield "level" were heavily biased unlike the ML methods, but its predicted yield response curve resembles the true response curve much more. It is well understood and established in the agronomic community that it is not yield "level", but the slope of the yield response curve that determins EONR. Therefore, it is not surprising that the failure by the ML methods to estimate site-specific yield response curve for this location accurately resulted in poor-performing input recommendation for this location. 

Severe underestimation of the impact of nitrogen on yield is not just for the single location. Figure \@ref(fig:treatment-effect) plots true and estiamted treatment effects of four treatments (<span style = "color: blue;"> Xiaofei, list cases here</span>) by model for all the locations (1440) within a single field for a single simulation round. It shows that the machine learning models severely underestimated the treatment effects at all N levels, resulting in severe underestimation of site-specific EONR.  This pattern is also observed in another simulation study by \@ref(@kakimoto2022) and also an empirical study by \@ref(Alfonso). In contrast, SER model did a much better job in treatment effect prediction, particularly at the low N levels. OLS model's estimated treatment effects were less biased compared to machine learning models, but it is much less accurate compared to SER. Due to the flexibility of the ML methods, it is easy for them to come up with wrong explanations to yield variations. As we saw earlier, the ML models explaind yield variations better (lower RMSE of yield) even though they fail to recognize the impact of nitrogen on yield. The ML models found it more beneficial to let the other variables explain the variations in yield than nitrogen.\footnote{Note that as the nitrogen level increases, the impact of nitrogen on yield declines and it is almost zero at the higher experimental nitrogen levels.} This illustrating example above is not just a outlier that we cherry-picked. Figure \@ref() shows the the density plot of the average ratio of estimated EONR to the true EONR by model for all the simulation rounds. As you can see, the ML methods tend to severely underestiamte EONR on average. 

## OLS vs. SER: Statistical efficiency is money 

It is also interesting to compare the OLS and SER results. It is well-established that SER is more statistically efficient than simple OLS in the presence of unknown spatial data autocorrrelation, which is a very common in OFPE data. This advantage of SER does not seem to have received much attention as it is just a statistical property, economist have a tendency to focus on unbiasedness and consistency issues more than efficiency. However, in the context of site-specific EONR estiamtion, statistical efficiency means money. The more accurately estimated coefficients are, the more accurately site-specific EONRs are estimated, leading to a higher profit. While \@ref(anselin) bluh bluh, they did not do it right. Our results show that improving statistical efficiency by taking into account the spatial autocorrelation of the error term can lead to a substantial increase in profit by VRA. The profit of SER model is higher than OLS model by $\$$`r (mean_data[field_size=="37.3 ha"&model=="SER", profit] - mean_data[field_size=="37.3 ha"&model=="OLS", profit]) %>% round(2)` ha$^{-1}$, $\$$`r (mean_data[field_size=="18.7 ha"&model=="SER", profit] - mean_data[field_size=="18.7 ha"&model=="OLS", profit]) %>% round(2)` ha$^{-1}$, and $\$$`r (mean_data[field_size=="9.3 ha"&model=="SER", profit] - mean_data[field_size=="9.3 ha"&model=="OLS", profit]) %>% round(2)` ha$^{-1}$ for large, medium, and small fields, respectively. To our knowledge, there is no 


## Field size

How robust are the results to different field sizes? Figure \@ref(fig:comb-boxplot-all) panels (B) and (C) showed the simulation results for medium (18.7 ha) and small (9.3 ha) sized fields.

- The result pattern that machine learning models have better yield predictions but worse economic performances compared to traditional regression models was generally robust to field sizes. 
- But machine learning models' economic performances catch up when field size decreases. Especially, BRF model outperformed OLS model in EONR prediction and profit performance in small and medium fields. Though BRF model's profit was still lower than SER, the profit gap between BRF and SER reduced from $\$$`r (mean_data[field_size=="37.3 ha"&model=="SER", profit] - mean_data[field_size=="37.3 ha"&model=="BRF", profit]) %>% round(2)` ha$^{-1}$ in large field to $\$$`r (mean_data[field_size=="18.7 ha"&model=="SER", profit] - mean_data[field_size=="18.7 ha"&model=="BRF", profit]) %>% round(2)` ha$^{-1}$ in medium field and $\$$`r (mean_data[field_size=="9.3 ha"&model=="SER", profit] - mean_data[field_size=="9.3 ha"&model=="BRF", profit]) %>% round(2)` ha$^{-1}$ in small field.
- The results may suggest machine learning models (especially BRF) apply better in small fields' data analysis. But since under the context of current farming practice most production fields are larger than the smallest field (9.3 ha) scenario in our simulation, SER model appears to be the economically best option. 

## Robustness to yield generating process

- The true yield generating process used in our simulation, quadratic-plateau function, is the most established corn yield response pattern demonstrated in the agronomy literature. But there are also some other corn response functional forms found in existing studies. In case somebody criticize us on this point, we also tried several other corn yield response functions: Mitscherlich‐Baul, quadratic, ...



`r run_pagebreak()`

# Conclusions

So, we should be cautious about the pitfall of machine learning models' good yield predicting performances. Almost all existing studies use yield prediction performance as the measure of yield estimation models. This can be very misleading and cost producers a lot when it is used in developing input management recommendations, since models with good yield prediction can have bad profit at the same time.


`r run_pagebreak()`

# References

`r run_pagebreak()`

# Figures {-}

`r run_pagebreak()`

```{r comb-boxplot-all, fig.cap="The estimation performances of machine learning models (RF, RF_b, BRF) and traditional regression models (OLS, SER) over 1,000 simulations for: (A) large field (37.3 ha), (B) medium field (18.7 ha), and (C) small field (9.3 ha). The performance measurements include: (1) out-of-sample yield prediction RMSE, (2) out-of-sample EONR prediction RMSE, and (3) profit resultant from the predicted EONR.", fig.height=8.5, fig.width=7, echo=FALSE, cache=FALSE}
(comb_boxplot_large + ggtitle("(A) large field")) / (comb_boxplot_medium + ggtitle("(B) medium field")) / (comb_boxplot_small + ggtitle("(C) small field"))
```

```{r single-simu-illustrate, fig.cap="The estimation performances of one example simulation, large field (37.3 ha). Each dot represents a location of the field.", fig.height=8.5, fig.width=7, echo=FALSE, cache=FALSE}
(single_simu_yield + ggtitle("(A)")) / (single_simu_EONR + ggtitle("(B)"))
```

```{r yield-curves, fig.cap="Estimated yield response curves at a specific location", fig.height=8.5, fig.width=7, echo=FALSE, cache=FALSE}
include_graphics(here("Shared/Graphs/802_yield.png"))
```

```{r treatment-effect, fig.cap="", echo=FALSE, fig.height=8.5, fig.width=7, cache=FALSE}
include_graphics(here("Shared/Graphs/treatment_sim_58.png"))
```

# Tables {-}

```{r extreme-percent, echo=FALSE}
# knitr::kable(mean_data, format = "markdown", caption = "Summary Statistics")
```



